{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f142836",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89e1a836",
   "metadata": {},
   "source": [
    "Ajoute des bibliotheque necessaire pour ce travail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303a978",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fcf44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\taleb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m✘ No compatible package found for 'fr_core_news_md-3.8.0' (spaCy\n",
      "v3.8.7)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import yake\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "!python -m spacy download fr_core_news_md-3.8.0\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61ce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir une année\n",
    "year = 1939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451034f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<yake.core.yake.KeywordExtractor at 0x1d9e0e49cd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantier l'extracteur de mots clés\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"fr\", top=50)\n",
    "kw_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3ecd65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lister les Fichiers de 1936\n",
    "data_path = '../../data'\n",
    "txt_path = '../../data/txt'\n",
    "txts = [f for f in os.listdir(txt_path) if os.path.isfile(os.path.join(txt_path, f)) and str(year) in f]\n",
    "len(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0e98489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour stocker les mots par fichier\n",
    "all_keywords = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47f80073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CHHÔNOGRAPHE SPORTS CHROMÉ', np.float64(0.008433594656983056)), ('SPORTS CHROMÉ INCASSABLE', np.float64(0.008433594656983056)), ('rue', np.float64(0.010347233650986084)), ('Rossel', np.float64(0.01588836443217654)), ('CHROMÉ INCASSABLE INOXVDAm.F', np.float64(0.020867342769277143)), ('SOLDATS SOLIDE CHHÔNOGRAPHE', np.float64(0.023285491815114096)), ('SOLIDE CHHÔNOGRAPHE SPORTS', np.float64(0.023285491815114096)), ('lait Libby', np.float64(0.03398297642859214)), ('Tél', np.float64(0.034022880589899746)), ('CHHÔNOGRAPHE SPORTS', np.float64(0.03670564141807278)), ('Arnaud', np.float64(0.039818583046681816)), ('Jacques', np.float64(0.04029857518614604)), ('Achat', np.float64(0.04100856119107712)), ('lait', np.float64(0.04177626888125794)), ('SPORTS CHROMÉ', np.float64(0.04199285313751565)), ('CHROMÉ INCASSABLE', np.float64(0.04199285313751565)), ('vendre', np.float64(0.04224344554163701)), ('Agence Rossel', np.float64(0.04573119671817946)), ('Quo', np.float64(0.045874696551939424)), ('Libby', np.float64(0.046137102303082975)), ('Ecrire Agence Rossel', np.float64(0.04654505847402243)), ('Tours', np.float64(0.056651544603336455)), ('BEAUX BRILLANTS rue', np.float64(0.05786077320120787)), ('ans', np.float64(0.05902432013742092)), ('uno', np.float64(0.060473418535414034)), ('rue Cornet', np.float64(0.06054525320530787)), ('DECEMBRE', np.float64(0.06091357512709739)), ('Henri do Laruns', np.float64(0.061082353393617256)), ('Jour', np.float64(0.06340570931011656)), ('Henri', np.float64(0.0635995576551438)), ('Maman', np.float64(0.06538772371810345)), ('pur', np.float64(0.07011662895715289)), ('Mol', np.float64(0.07023886310259714)), ('BRILLANTS rue Marchè-aux', np.float64(0.0712788681708411)), ('BIJOUX BRILLANTS', np.float64(0.07144058694017248)), ('prix', np.float64(0.07166658662791577)), ('jeune flllo', np.float64(0.07176704220693056)), ('METALLIQUE CHROMÉ', np.float64(0.07378562539116493)), ('aveo', np.float64(0.07603653548399777)), ('Bruxelles', np.float64(0.08197183780451614)), ('bon', np.float64(0.0820374990982564)), ('Ecrire', np.float64(0.0820994740848819)), ('Garantie sur facture', np.float64(0.08605462694117481)), ('INCASSABLE INOXVDAm.F', np.float64(0.0871352495786981)), ('BIJOUX', np.float64(0.08807521345437433)), ('BRILLANTS', np.float64(0.08871565099160772)), ('Laruns', np.float64(0.08951363003498773)), ('jeune', np.float64(0.09443367191268517)), ('flllo', np.float64(0.0944749354260717)), ('mère', np.float64(0.09526701824153819))]\n"
     ]
    }
   ],
   "source": [
    "# Parcourt tous les fichiers texte du dossier, lit leur contenu,\n",
    "# extrait les mots-clés avec kw_extractor et les stocke dans un dictionnaire\n",
    "\n",
    "for this_file in txts:\n",
    "    with open(os.path.join(txt_path, this_file), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        # print(f\"Aperçu de {this_file}\")\n",
    "        keywords = kw_extractor.extract_keywords(text)\n",
    "        all_keywords[this_file] = keywords\n",
    "\n",
    "print(keywords)  # Affiche les mots-clés extraits du dernier fichier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1932610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords (Idem que dans s1)\n",
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\",\n",
    "       \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \"sous\",\n",
    "       \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \"cela\", \"non\",\n",
    "       \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \"depuis\", \"autres\",\n",
    "       \"van\", \"het\", \"autre\", \"jusqu\",\"bon\", \"vers\",\"bruxelles\",\"rue\",\"TÉL\",\"tél\",\"ANS\",\"très\",\"BRUXELLES\",\"TRÈS\"]\n",
    "sw = set(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2856c001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'■ 2, et 3 JANyiÉR 1 9 •JJ iy-^ tJT» v\\'.^- -..\\'. *;rV| y#»- **••»*■\\'» V».. \\'’.^V\\'\\' \\'.“ ,. f. * >/. * v* •■\\'. •; * .• \"ï..-.\\'.\\'rv. w->*v.v. :~r-:.*. ■\\'S.XZ-:EQOLE\\'sp^cIftllBéo\\'dé** v,-\". \\'.v onnu«vmtiR-. iESOIR v,*ffàÿl«ïE*r é.\\'. • w -1\\' Wf^^XX‘% ] XXM | ït ; PEDICURIE Maurice i WAFELLMAN ^complète\\',, tüÿorle ,*t pfàtiç, 6i*i> Mtàoota. ÿt|.-. 87.S5.gO. /. 33403 B TOUSSER SANS; ARRÊT est extrêmement cnnuÿeux et douloureux par le fait que Vous êtes .tétine t).des rapports verbaux\\'continuels avec là-'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stocker le contenu de ces fichiers dans une liste\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(os.path.join(txt_path, txt), 'r', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "# Ecrire tout le contenu dans un fichier temporaire\n",
    "temp_path = '../../data/tmp'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "with open(os.path.join(temp_path, f'{year}.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "# Imprimer le contenu du fichier et constater les \"déchets\"\n",
    "with open(os.path.join(temp_path, f'{year}.txt'), 'r', encoding='utf-8') as f:\n",
    "    before = f.read()\n",
    "\n",
    "before[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4522b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(year, folder=None):\n",
    "    if folder is None:\n",
    "        input_path = f\"{year}.txt\"\n",
    "        output_path = f\"{year}_clean.txt\"\n",
    "    else:\n",
    "        input_path = f\"{folder}/{year}.txt\"\n",
    "        output_path = f\"{folder}/{year}_clean.txt\"\n",
    "    output = open(output_path, \"w\", encoding='utf-8')\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        words = nltk.wordpunct_tokenize(text)\n",
    "        kept = [w.upper() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "        kept_string = \" \".join(kept)\n",
    "        output.write(kept_string)\n",
    "    return f'Output has been written in {output_path}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa66b792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output has been written in ../../data/tmp/1939_clean.txt!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(year, folder=temp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
